{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/stable-diffusion-pytorch/blob/paddle/demo.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgkJdPCbVjf6"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b paddle https://github.com/camenduru/stable-diffusion-pytorch\n",
        "%cd /content/stable-diffusion-pytorch\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://passl.bj.bcebos.com/models/ViT-B-32.pdparams -d /content/stable-diffusion-pytorch/data/ckpt -o clip.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/stable-diffusion-pytorch\n",
        "import paddle\n",
        "from stable_diffusion_pytorch import Tokenizer, CLIP, Encoder, Decoder, Diffusion\n",
        "from stable_diffusion_pytorch import util\n",
        "import warnings\n",
        "\n",
        "state_dict = paddle.load(util.get_file_path('ckpt/clip.pt'))\n",
        "clip = CLIP().to('cpu')\n",
        "clip.load_dict(state_dict)\n",
        "tokenizer = Tokenizer()\n",
        "prompt = \"a photograph of an astronaut riding a horse\"\n",
        "prompts = [prompt]\n",
        "tokens = tokenizer.encode_batch(prompts)\n",
        "tokens = paddle.to_tensor(tokens, dtype='int64', place=paddle.CPUPlace())\n",
        "context = clip(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fGOopQsDS-7U"
      },
      "outputs": [],
      "source": [
        "from stable_diffusion_pytorch import model_loader\n",
        "models = model_loader.preload_models('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x_dhQfFYXoPu"
      },
      "outputs": [],
      "source": [
        "from stable_diffusion_pytorch import pipeline\n",
        "\n",
        "prompt = \"a photograph of an astronaut riding a horse\"  #@param { type: \"string\" }\n",
        "prompts = [prompt]\n",
        "\n",
        "uncond_prompt = \"\"  #@param { type: \"string\" }\n",
        "uncond_prompts = [uncond_prompt] if uncond_prompt else None\n",
        "\n",
        "upload_input_image = False  #@param { type: \"boolean\" }\n",
        "input_images = None\n",
        "if upload_input_image:\n",
        "    from PIL import Image\n",
        "    from google.colab import files\n",
        "    print(\"Upload an input image:\")\n",
        "    path = list(files.upload().keys())[0]\n",
        "    input_images = [Image.open(path)]\n",
        "\n",
        "strength = 0.8  #@param { type:\"slider\", min: 0, max: 1, step: 0.01 }\n",
        "\n",
        "do_cfg = True  #@param { type: \"boolean\" }\n",
        "cfg_scale = 7.5  #@param { type:\"slider\", min: 1, max: 14, step: 0.5 }\n",
        "height = 512  #@param { type: \"integer\" }\n",
        "width = 512  #@param { type: \"integer\" }\n",
        "sampler = \"k_lms\"  #@param [\"k_lms\", \"k_euler\", \"k_euler_ancestral\"]\n",
        "n_inference_steps = 50  #@param { type: \"integer\" }\n",
        "\n",
        "use_seed = False  #@param { type: \"boolean\" }\n",
        "if use_seed:\n",
        "    seed = 42  #@param { type: \"integer\" }\n",
        "else:\n",
        "    seed = None\n",
        "\n",
        "pipeline.generate(prompts=prompts, uncond_prompts=uncond_prompts,\n",
        "                  input_images=input_images, strength=strength,\n",
        "                  do_cfg=do_cfg, cfg_scale=cfg_scale,\n",
        "                  height=height, width=width, sampler=sampler,\n",
        "                  n_inference_steps=n_inference_steps, seed=seed,\n",
        "                  models=models, device='cuda', idle_device='cpu')[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "iDI2dKfRWTId"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
